{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEzGIILJj0UO"
      },
      "source": [
        "###**Fairness Auditing and Mitigation in a Criminal Justice Setting (COMPAS)**\n",
        "\n",
        "###**PART 1: Fairness Definitions in Context**\n",
        "\n",
        "**Scenario A:**\n",
        "\n",
        "The concern in this scenario is that if the model continually fails to identify true high-risk individuals within a particular racial group, it would deny them access to helpful resources. To minimize this, we need to equalize the True Positive Rate across the groups. This will ensure that we can focus on providing high-risk individuals in each group with the opportunity to receive the necessary help, while avoiding overprediction.\n",
        "\n",
        "**Scenario B:**\n",
        "\n",
        "The concern in this scenario is that if a racial group has a large number of false positives, individuals within this group will be subjected to repeated check-ins even when they do not require it. To bring this down, we can equalize the False Positive Rate across the groups. This ensures that the false positive rates for each racial group are comparable and no one racial group bears the burden of the repeated check-ins. Lowering FPR may increase FNR; however, in this scenario, the concern is that a higher FPR for a group can burden its members, and the requirement is to lower that. Hence, in the tradeoff between lowering FPR and increasing FNR, I believe lowering FPR should be favoured."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0w3Viz0jo3Y",
        "outputId": "2e288781-c8c3-4473-ca44-a0e1b648a1c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (1.16.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n",
            "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fairlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c08_F7HIm2_8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from fairlearn.metrics import MetricFrame, selection_rate, false_positive_rate, false_negative_rate\n",
        "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds\n",
        "\n",
        "from fairlearn.reductions import TruePositiveRateParity, FalsePositiveRateParity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kxK-is1mnUf5"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# Config & Data\n",
        "# -----------------------\n",
        "DATA_PATH = \"compas.csv\"\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.3\n",
        "TARGET_COL = \"ReoffendedWithinTwoYears\"\n",
        "SENSITIVE_COL = \"Race\"\n",
        "\n",
        "REQUIRED_COLS = [\n",
        "    \"Sex\", \"Race\", \"Prior Offenses\", \"Under 25\", \"ChargeDegree\",\n",
        "    \"COMPASPredictedDecileScore\", \"ReoffendedWithinTwoYears\"\n",
        "]\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    raise FileNotFoundError(f\"Missing file: {DATA_PATH}\")\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Dataset missing columns: {missing}\")\n",
        "\n",
        "df = df[REQUIRED_COLS].dropna(subset=[SENSITIVE_COL, TARGET_COL]).copy()\n",
        "y = df[TARGET_COL].astype(int).values\n",
        "A = df[SENSITIVE_COL].astype(str).values\n",
        "X = df.drop(columns=[TARGET_COL])\n",
        "\n",
        "X_tr, X_te, y_tr, y_te, A_tr, A_te = train_test_split(\n",
        "    X, y, A, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wwF-ET-RnUUq"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "\n",
        "numeric_features = [\"COMPASPredictedDecileScore\"]\n",
        "categorical_features = [c for c in X.columns if c not in numeric_features]\n",
        "\n",
        "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_features),\n",
        "        (\"cat\", ohe, categorical_features),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SOSwXvQ8nYpC"
      },
      "outputs": [],
      "source": [
        "# Metric helpers\n",
        "\n",
        "def compute_metrics(y_true, y_pred, sens):\n",
        "    \"\"\"Return (MetricFrame, gaps_dict) for accuracy, selection_rate, FPR, FNR.\"\"\"\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy_score,\n",
        "        \"selection_rate\": selection_rate,\n",
        "        \"false_positive_rate\": false_positive_rate,\n",
        "        \"false_negative_rate\": false_negative_rate\n",
        "    }\n",
        "    mf = MetricFrame(metrics=metrics, y_true=y_true, y_pred=y_pred, sensitive_features=sens)\n",
        "    gaps = {\n",
        "        \"gap_selection_rate\": mf.difference(method=\"between_groups\")[\"selection_rate\"],\n",
        "        \"gap_fpr\": mf.difference(method=\"between_groups\")[\"false_positive_rate\"],\n",
        "        \"gap_fnr\": mf.difference(method=\"between_groups\")[\"false_negative_rate\"],\n",
        "    }\n",
        "    return mf, gaps\n",
        "\n",
        "\n",
        "##Helper method to print metrics and gaps in metrics as a table\n",
        "def print_metrics(mf, gaps, n):\n",
        "  print(\"\\n==========\" + n + \" Model Metrics ==========\")\n",
        "  bg = mf.by_group if isinstance(mf.by_group, pd.DataFrame) else pd.DataFrame(mf.by_group)\n",
        "  bg[\"true_positive_rate\"] = 1 - bg[\"false_negative_rate\"] # Corrected line\n",
        "  o = pd.DataFrame({k: [v] for k, v in mf.overall.items()});\n",
        "  o[\"true_positive_rate\"] = 1 - o[\"false_negative_rate\"]\n",
        "  o.index = [\"overall\"]\n",
        "  print(pd.concat([o, bg], axis=0).to_string())\n",
        "\n",
        "  print(\"\\n==========  Gaps in Metrics ==========  \")\n",
        "\n",
        "  # print(gaps_base)\n",
        "  gaps_pd = pd.DataFrame({k: [v] for k, v in gaps.items()}, index = [\"gaps_base\"]);\n",
        "  print()\n",
        "  print(gaps_pd.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5wd7CranqXO"
      },
      "source": [
        "###**PART 2: Baseline Model and Fairness Audit**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuYgi4AOo5F9"
      },
      "source": [
        "**Step 1: Build the pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "TOSZR2xxncx1",
        "outputId": "1f7ffda3-3a1a-41d7-800b-da9957503bc7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pre&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
              "                                                  [&#x27;COMPASPredictedDecileScore&#x27;]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                sparse_output=False),\n",
              "                                                  [&#x27;Sex&#x27;, &#x27;Race&#x27;,\n",
              "                                                   &#x27;Prior Offenses&#x27;, &#x27;Under 25&#x27;,\n",
              "                                                   &#x27;ChargeDegree&#x27;])])),\n",
              "                (&#x27;clf&#x27;, LogisticRegression(max_iter=200, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;pre&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
              "                                                  [&#x27;COMPASPredictedDecileScore&#x27;]),\n",
              "                                                 (&#x27;cat&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                sparse_output=False),\n",
              "                                                  [&#x27;Sex&#x27;, &#x27;Race&#x27;,\n",
              "                                                   &#x27;Prior Offenses&#x27;, &#x27;Under 25&#x27;,\n",
              "                                                   &#x27;ChargeDegree&#x27;])])),\n",
              "                (&#x27;clf&#x27;, LogisticRegression(max_iter=200, random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>pre: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for pre: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
              "                                 [&#x27;COMPASPredictedDecileScore&#x27;]),\n",
              "                                (&#x27;cat&#x27;,\n",
              "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                               sparse_output=False),\n",
              "                                 [&#x27;Sex&#x27;, &#x27;Race&#x27;, &#x27;Prior Offenses&#x27;, &#x27;Under 25&#x27;,\n",
              "                                  &#x27;ChargeDegree&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;COMPASPredictedDecileScore&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Sex&#x27;, &#x27;Race&#x27;, &#x27;Prior Offenses&#x27;, &#x27;Under 25&#x27;, &#x27;ChargeDegree&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=200, random_state=42)</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('pre',\n",
              "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
              "                                                  ['COMPASPredictedDecileScore']),\n",
              "                                                 ('cat',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore',\n",
              "                                                                sparse_output=False),\n",
              "                                                  ['Sex', 'Race',\n",
              "                                                   'Prior Offenses', 'Under 25',\n",
              "                                                   'ChargeDegree'])])),\n",
              "                ('clf', LogisticRegression(max_iter=200, random_state=42))])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline = Pipeline(steps=[(\"pre\", preprocess), (\"clf\", LogisticRegression(max_iter=200, C=1.0, solver=\"lbfgs\", random_state=RANDOM_STATE))])\n",
        "\n",
        "# Fit on training data\n",
        "baseline.fit(X_tr, y_tr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RAkPLBDo9VE"
      },
      "source": [
        "**Step 2: Predict on test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4HlqwF-pBvr",
        "outputId": "d08fd6c0-1e22-4610-f645-cc5b7804b4ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==========Baseline Model Metrics ==========\n",
            "                  accuracy  selection_rate  false_positive_rate  false_negative_rate  true_positive_rate\n",
            "overall           0.665589        0.394457             0.253154             0.433402            0.566598\n",
            "African-American  0.665480        0.535587             0.368705             0.301056            0.698944\n",
            "Asian             0.500000        0.000000             0.000000             1.000000            0.000000\n",
            "Caucasian         0.675214        0.272080             0.177677             0.570342            0.429658\n",
            "Hispanic          0.616915        0.184080             0.121739             0.732558            0.267442\n",
            "Native American   0.571429        0.142857             0.000000             0.750000            0.250000\n",
            "Other             0.707317        0.186992             0.055556             0.627451            0.372549\n",
            "\n",
            "==========  Gaps in Metrics ==========  \n",
            "\n",
            "           gap_selection_rate   gap_fpr   gap_fnr\n",
            "gaps_base            0.535587  0.368705  0.698944\n"
          ]
        }
      ],
      "source": [
        "y_pred_base = baseline.predict(X_te)\n",
        "\n",
        "# Compute metrics\n",
        "mf_base, gaps_base = compute_metrics(y_te, y_pred_base, A_te)\n",
        "\n",
        "# Print results\n",
        "print_metrics(mf_base, gaps_base, \"Baseline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rKebnNIol6B"
      },
      "source": [
        "**Step 3: Interpretation**\n",
        "\n",
        "The disparities are detailed below.\n",
        "\n",
        "For this interpretation I will look at mostly African-American and Caucasian scores to show the disparity.\n",
        "\n",
        "Consider the selcetion metrics for African-American community vs. the Caucasian community.\n",
        "\n",
        "| Racial Group | Selection Rate |\n",
        "|----------|----------|\n",
        "| African-American | 0.535587    |\n",
        "| Caucasian   | 0.272080 |\n",
        "\n",
        "The selection rate for the African-American community is atleast twice as larger than the selection rate for the Caucasian community.\n",
        "\n",
        "\n",
        "According to the FPR rate metrics for African-American vs. Caucasian,\n",
        "\n",
        "| Racial Group | FPR |\n",
        "|----------|----------|\n",
        "| African-American | 0.368705    |\n",
        "| Caucasian   | 0.177677   |\n",
        "\n",
        "Similar to the selection rates, here the FPR value for African-Americans is more than twice the same value for Caucasians, i.e., the model is predicting more African-Americans as high-risk individuals when they are not.\n",
        "\n",
        "According to the FNR metrics for African-American vs. Caucasian,\n",
        "\n",
        "| Racial Group | FNR |\n",
        "|----------|----------|\n",
        "| African-American | 0.301056   |\n",
        "| Caucasian   | 0.570342  |\n",
        "\n",
        "This indicates that the number of individuals in the Caucasian community that are incorrectly labeled as low-risk when they are actually high-risk is much more than in the African-American community.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VUPB7kprcH5"
      },
      "source": [
        "###**PART 3: Mitigating Bias**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0dC6TwUrjiS"
      },
      "source": [
        "**Step 1: Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kvzlTnqlrmmF"
      },
      "outputs": [],
      "source": [
        "Xtr_t = baseline.named_steps[\"pre\"].transform(X_tr)\n",
        "Xte_t = baseline.named_steps[\"pre\"].transform(X_te)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B6hHv64Crz-G"
      },
      "outputs": [],
      "source": [
        "def fit_mitigated(constraint_name, constraint_ctor, Xtr_t, Xte_t, y_tr, y_te, A_tr, A_te):\n",
        "    \"\"\"Fit a mitigated model and return (name, MetricFrame, gaps).\"\"\"\n",
        "    constraint = constraint_ctor()\n",
        "    mit = ExponentiatedGradient(\n",
        "        estimator=LogisticRegression(max_iter=200, C=1.0, solver=\"lbfgs\", random_state=RANDOM_STATE),\n",
        "        constraints=constraint,\n",
        "        eps=0.01,\n",
        "        max_iter=50,\n",
        "        sample_weight_name=\"sample_weight\",\n",
        "    )\n",
        "    mit.fit(Xtr_t, y_tr, sensitive_features=A_tr)\n",
        "    y_hat = mit.predict(Xte_t)\n",
        "    return y_hat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRBMiHxfr00n"
      },
      "source": [
        "**Step 2: Train & Predict**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8GUXRALmr4rf"
      },
      "outputs": [],
      "source": [
        "mitigation_TPR_yhat = fit_mitigated(\n",
        "    \"TPR Parity\", TruePositiveRateParity, Xtr_t, Xte_t, y_tr, y_te, A_tr, A_te\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "P2tWo4iKykle"
      },
      "outputs": [],
      "source": [
        "mitigation_FPR_yhat = fit_mitigated(\n",
        "    \"FPR Parity\", FalsePositiveRateParity, Xtr_t, Xte_t, y_tr, y_te, A_tr, A_te\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj_ij7jPsdtD"
      },
      "source": [
        "**Step 3: Re-Audit**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKCGDMAKtC2t"
      },
      "source": [
        "Comparing model using TPR fairness constraint vs. baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAEDS2-nsQGM",
        "outputId": "92f621ff-c72f-4850-975a-eccba5e0388c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==========TPR Parity Model Metrics ==========\n",
            "                  accuracy  selection_rate  false_positive_rate  false_negative_rate  true_positive_rate\n",
            "overall           0.664203        0.381062             0.242220             0.449795            0.550205\n",
            "African-American  0.659253        0.406584             0.244604             0.434859            0.565141\n",
            "Asian             0.625000        0.375000             0.250000             0.500000            0.500000\n",
            "Caucasian         0.663818        0.349003             0.248292             0.482890            0.517110\n",
            "Hispanic          0.641791        0.368159             0.260870             0.488372            0.511628\n",
            "Native American   0.714286        0.285714             0.000000             0.500000            0.500000\n",
            "Other             0.747967        0.357724             0.166667             0.372549            0.627451\n",
            "\n",
            "==========  Gaps in Metrics ==========  \n",
            "\n",
            "           gap_selection_rate  gap_fpr   gap_fnr\n",
            "gaps_base            0.120869  0.26087  0.127451\n"
          ]
        }
      ],
      "source": [
        "m_tprmodel, gs_tprmodel = compute_metrics(y_te, mitigation_TPR_yhat, A_te)\n",
        "print_metrics(m_tprmodel, gs_tprmodel, \"TPR Parity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoPAM8afuP59"
      },
      "source": [
        "I used True Positive Rate for the scenario A because we needed to prioritize identitfication of high risk individuals across all racial groups so that they can get the helpful resources and not overpredict.\n",
        "\n",
        "Now, we can calculate TPR by calculating 1 - FNR.\n",
        "\n",
        "|         |African-American TPR Values    | Caucasian TPR Values      |\n",
        "|----------| ----------|----------|\n",
        "|Baseline Model| 0.698944 | 0.429658   |\n",
        "| TPRParity Model| 0.565141 | 0.517110  |\n",
        "\n",
        "We can see how the TPR value has evened out in the TPRParity Model now compared to the baseline model.\n",
        "\n",
        "THe gap in the TPR value has also come down from 0.698944 in baseline model to 0.127451 in the TPRParity model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToLHPYUqt0ZJ",
        "outputId": "53f1c56a-e77f-4f0d-8e19-8f4adab79cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==========FPR Parity Model Metrics ==========\n",
            "                  accuracy  selection_rate  false_positive_rate  false_negative_rate  true_positive_rate\n",
            "overall           0.660970        0.416628             0.277544             0.413934            0.586066\n",
            "African-American  0.654804        0.453737             0.296763             0.392606            0.607394\n",
            "Asian             0.750000        0.250000             0.000000             0.500000            0.500000\n",
            "Caucasian         0.659544        0.401709             0.293850             0.418251            0.581749\n",
            "Hispanic          0.661692        0.328358             0.208696             0.511628            0.488372\n",
            "Native American   0.714286        0.285714             0.000000             0.500000            0.500000\n",
            "Other             0.715447        0.325203             0.166667             0.450980            0.549020\n",
            "\n",
            "==========  Gaps in Metrics ==========  \n",
            "\n",
            "           gap_selection_rate   gap_fpr   gap_fnr\n",
            "gaps_base            0.203737  0.296763  0.119022\n"
          ]
        }
      ],
      "source": [
        "m_fprmodel, gs_fprmodel = compute_metrics(y_te, mitigation_FPR_yhat, A_te)\n",
        "print_metrics(m_fprmodel, gs_fprmodel, \"FPR Parity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nESrub9Qvsou"
      },
      "source": [
        "I used the False Positive Rate as my fairness metric for Scenario B.\n",
        "\n",
        "|     |African-American FPR Values     | Caucasian FPR Values     |\n",
        "|----------| ----------|----------|\n",
        "|Baseline Model| 0.368705 | 0.177677   |\n",
        "| FPRParity Model| 0.296763  | 0.293850 |\n",
        "\n",
        "When performing the mitigation based on the FalsePositiveRateParity, from the model that had mitigation performed we see that the values for false positives is much more evened out amongst the African Americans and the Caucasians. This a good improvement over the FPR values in the baseline model. We also see an improvement in the greatest gap between FPR in the baseline model(0.368705) and the model on which mitigation was run(0.296763)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXubfE4fw4Ko"
      },
      "source": [
        "**Conclusion:** Both mitigation methods significantly reduced the disparities in TPR and FPR values across groups observed in the baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDxjQ4Dxw8S3"
      },
      "source": [
        "###**Part 4: Analysis & Recommendation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGxGZJBGxY9I",
        "outputId": "a189043d-bb72-476f-fb21-859e939a7164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Comparison (Baseline vs two mitigations) ===\n",
            "                  model  overall_accuracy  gap_selection_rate  gap_fpr  gap_fnr\n",
            "               Baseline          0.665589            0.535587 0.368705 0.698944\n",
            " TruePositiveRateParity          0.664203            0.120869 0.260870 0.127451\n",
            "FalsePositiveRateParity          0.660970            0.203737 0.296763 0.119022\n"
          ]
        }
      ],
      "source": [
        "rows = [{\n",
        "    \"model\": \"Baseline\",\n",
        "    \"overall_accuracy\": mf_base.overall[\"accuracy\"],\n",
        "    \"gap_selection_rate\": gaps_base[\"gap_selection_rate\"],\n",
        "    \"gap_fpr\": gaps_base[\"gap_fpr\"],\n",
        "    \"gap_fnr\": gaps_base[\"gap_fnr\"],\n",
        "}]\n",
        "\n",
        "mitigation_runs = [\n",
        "    (\"TruePositiveRateParity\", m_tprmodel, gs_tprmodel),\n",
        "    (\"FalsePositiveRateParity\", m_fprmodel, gs_fprmodel),\n",
        "]\n",
        "\n",
        "for name, mf_m, gaps_m in mitigation_runs:\n",
        "    rows.append({\n",
        "        \"model\": name,\n",
        "        \"overall_accuracy\": mf_m.overall[\"accuracy\"],\n",
        "        \"gap_selection_rate\": gaps_m[\"gap_selection_rate\"],\n",
        "        \"gap_fpr\": gaps_m[\"gap_fpr\"],\n",
        "        \"gap_fnr\": gaps_m[\"gap_fnr\"],\n",
        "    })\n",
        "\n",
        "compare_df = pd.DataFrame(rows)\n",
        "\n",
        "print(\"\\n=== Comparison (Baseline vs two mitigations) ===\")\n",
        "print(compare_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjedJr1TxHXW"
      },
      "source": [
        "(a) **The Comparison**\n",
        "\n",
        "As can be observed from the table above, we can see the gap between the selection rate, FRP and FNR have gone down significantly in the models on which mitigation was performed over the baseline model. We also observe that there has not been a drastic change in the accuracy between the three models.\n",
        "\n",
        "(b) **The Trade-off**\n",
        "\n",
        "From the metrics, the disparaties in FPR and TPR have come down significantly in the models which had included some fairness constraint when compared to the baseline model.\n",
        "\n",
        "For example, for the largest gap between groups in the baseline model for FPR value was 0.368705. However, when applying the FalsePositiveRateParity mitigation we see that this value has come down to 0.296763.\n",
        "\n",
        "Between the baseline model and the models which has undergone some mitigation techniques, there seems to be not much difference in the accuracy. The baseline model has an accuracy of 0.665589 while the model which had TruePositiveRateParity mitigation applied to it has a accuracy of 0.664203(which is an increase of 0.0013).\n",
        "Similarly for the model which had FalsePositiveRateParity mitigation applied to it has an accuracy of 0.660970 (which is a drop of 0.0046)\n",
        "\n",
        "(c) **The Recommendation**\n",
        "\n",
        "Based on the metrics, for scenario A, I would recommend the model that has undergone the mitigation technique with the True Positive Rate Parity fairness constraint. This is because we need to focus on identifying the right individuals across all groups who require the specialized help. Furthermore, using this fairness constraint in the mitigation technique, we observe a negligible change in the model's accuracy, as indicated by the metrics table, which suggests that we are not overpredicting and we need not over about a dramatic drop in accuracy.\n",
        "\n",
        "\n",
        "For scenario B, I recommend the model that has undergone the mitigation technique with the False Positive Rate Parity fairness constraint. This is because we need to ensure that we are not wasting our resources on individuals who may not be at high risk. If this is not followed, pne particular racial group may have a lot of false positive and thus individuals from a particular race may receive these continuous check-ins even if they are not actually at high risk. By equalizing this across groups, we ensure that this burden is not ill-proportioned on people from one racial background. It is observed from the metrics table that the mitigation technique using this metric will even out the FPR value across the races.\n",
        "\n",
        "(d) **Limitations & Next Steps**\n",
        "\n",
        " (1) One limitation I find is based on how ethnicity is defined in this dataset. Ethnicity is increasingly becoming a subjective term, as individuals often belong to multiple ethnicities or racial origins. A simple change to address this is to stop creating rigid categories into which we place people and adopt a more fluid format, allowing individuals to identify with multiple racial groups.\n",
        "\n",
        " (2) Another limitation is the use of \"ReoffendedWithinTwoYears\" as an accurate measure of a high-risk individual. Let us consider two individuals. One individual is charged with theft of an item from a store and has reoffended with the same charge within a two-year period. The second individual is accused of a much bigger crime that result in the loss of a life and they have reoffended within 3 or 4 years. In this case, the model might consider the second individual to be less high-risk than the first individual. To address this, the target variable needs to be a function of the degree of the charge and whether the individual has reoffended in the past 'x' number of years. This could create a much more robust prediction target.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
